<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en-us">
<head>
   <meta http-equiv="content-type" content="text/html; charset=utf-8" />
   <title>Joshua Chi's Blog</title>
   <meta name="author" content="Joshua Chi" />
   <!-- syntax highlighting CSS -->
   <link rel="stylesheet" href="/css/syntax.css" type="text/css" />

   <!-- Homepage CSS -->
   <link rel="stylesheet" href="/css/screen.css" type="text/css" media="screen, projection" />

		<!-- Google Analytics -->
		<script type="text/javascript">
		var _gaq = _gaq || [];
		_gaq.push(['_setAccount', 'UA-9434024-4']);
		_gaq.push(['_trackPageview']);

		(function() {
		var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
		ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
		var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
		})();
		</script>
		<!-- Google Analytics end -->
</head>
<body>

<div class="site">
  <div class="header">
    <a href="/">Free To Feel</a>
  </div>

<!--start of side bar-->
<div id="sidebar" >
	<img src='http://www.gravatar.com/avatar/81759b36bd906bbf803ce4a5ce84e643.png' />
	<br />
	Joshua Chi
    <div class="contact">
        <a href="http://twitter.com/Joshua_C/">twitter.com/Joshua_C</a><br />
				<a href="https://github.com/joshuachi">My Github</a><br />
				<a href="http://www.dachebang.com">搭车帮</a><br />
				<a href="http://www.leanprofile.com">Lean Profile</a><br />
				<a href="http://www.kiwitask.com">Find freelancer</a><br />
			</div>
			<div>
				<a href='http://www.freetofeel.com/archives.html'> Archived Posts</a>
			</div>
			<div class="rss">
                                <p><a href="http://feeds.feedburner.com/freetofeel"><img src="http://feeds.feedburner.com/~fc/freetofeel?bg=99CCFF&amp;fg=444444&amp;anim=0" height="26" width="88" style="border:0" alt="" /></a></p>
				<p>
				<a href="http://freetofeel.com/atom.xml">Subscribe(xml)</a>
				</p>
				<p>
				<a href="http://feeds.feedburner.com/FreeToFeel">Subscribe(feedburner)</a>
				</p>
			</div>	
		
			<p class='douban'>
				<script type="text/javascript" src="http://www.douban.com/service/badge/joshua_c/?show=collection&amp;select=random&amp;n=8&amp;columns=2&amp;hidelogo=yes&amp;cat=book|music" ></script> 
				</p>
</div>
<!--end of side bar-->

	<div id='content'>
		<div id="home">

<div class="post">
  <ul class="content">
		
			<div class="post" id="postid-/2011/06/12/nosql-db-try">
				<h3 class="title"><a href="/2011/06/12/nosql-db-try.html">Replace MySql Table with NoSQL DB</a></h3>
				
				<h4>Backgroud:</h4>


<p>I am not nosql fans. I don't have the habit to replace whole mysql db with nosql db. But if a mysql table can be replaced with nosql db and expensive queries are generated againest this table, I will give a try of nosql DB.</p>

<p>In our product, we have a unique user login log table to know how many users logined in a specify date. Here is the table structure:</p>

<pre>
  unique_login_logs: 
    _attributes:  {phpName: UniqueLoginLog}
    id:
    user_id: { type: integer }
    date: { type: date, index: true }
    created_at:
    _uniques:
      unique_date_type: [user_id, date]
</pre>


<p>The expensive query looks like:</p>

<pre>
select date, count(`user_id`) from unique_login_logs group by date order by date desc;'
</pre>


<p>And the other related operations will be save an entry into this table or check the user entry for a specify date is in the table or not. Nothing more.</p>

<h4>Choose NoSQL DB from <a href='http://en.wikipedia.org/wiki/NoSQL'>wiki page</a>: </h4>




<pre>
...
Key-value cache in RAM

    Citrusleaf database
    memcached
    Oracle Coherence
    Redis
    Tuple space
    Velocity

Key-value stores implementing the Paxos algorithm

    Keyspace

Key-value stores on disk

    BigTable
    CDB
    Citrusleaf database
    Dynomite
    Keyspace
    membase
    Memcachedb
    Redis
    Tokyo Cabinet
    TreapDB
    Tuple space
    MongoDB
...
</pre>


<p>For my feature request, I need a disk stored key-value system. I just spend 1 minute to take a look the MongoDB features. It meet my feature requirements. That's enough. If you know more about the other nosql DBs, of course you should choose the one which suit yours best.</p>

<h4>Try MongoDB</h4>


<p>Step 1: Install MongoDB(http://www.mongodb.org/display/DOCS/Quickstart+Unix);</p>

<p>Step 2: Simple demo testing:</p>

<p>create a new db:</p>

<pre>
use mydb;
</pre>


<p>Save an entry:</p>

<pre>
db.uniqueLoginLog.save({date: '2011-06-09', user_id: 101});
db.uniqueLoginLog.save({date: '2011-06-09', user_id: 111});
db.uniqueLoginLog.save({date: '2011-06-09', user_id: 102});
..
db.uniqueLoginLog.save({date: '2011-06-11', user_id: 100});
db.uniqueLoginLog.save({date: '2011-06-11', user_id: 101});
db.uniqueLoginLog.save({date: '2011-06-11', user_id: 102});
</pre>


<p>Group entries by date:</p>

<pre>
db.uniqueLoginLog.group(
           {key: { date:true },
            reduce: function(obj,prev) { prev.count ++; },
            initial: { count: 0 }
            });
            
</pre>


<p>The output looks like:</p>

<pre>
[
    {
        "date" : "2011-01-01",
        "count" : 3
    },
    {
        "date" : "2011-01-02",
        "count" : 3
    },
    {
        "date" : "2011-01-03",
        "count" : 1
    },
    {
        "date" : "2011-01-04",
        "count" : 1
    }
]
</pre>


<p></p>

<p>With the output, I can do the order in client.</p>

<h4>Install PHP Mongo Extension</h4>


<p>You can install Mongo PHP extension with pecl command line or install it <a href='http://pecl.php.net/package/mongo'>manually</a></p>

<pre>
> pecl search mongo
Retrieving data...0%
Matched packages, channel pecl.php.net:
=======================================
Package Stable/(Latest) Local
mongo   1.1.4 (stable)        MongoDB database driver

> pecl install mongo
</pre>




<h4>Get stored items with php function</h4>


<p>PHP code:</p>

<pre>
$m = new Mongo();

$db = $m->mydb;

$collection = $db->uniqueLoginLog;


$obj = array('date'=> '2011-06-09', 'user_id'=> 101);
$collection->insert($obj);



$keys = array("date" => 1);
$initial = array("count" => 0);
$reduce = "function(obj,prev) { prev.count ++; }";
$g = $collection->group($keys, $initial, $reduce);

var_dump($g);

</pre>


<p>Output looks like:</p>

<pre>
array(4) {
  ["retval"]=>
  array(3) {
    [0]=>
    array(2) {
      ["date"]=>
      string(10) "2011-06-09"
      ["count"]=>
      float(17)
    }
    [1]=>
    array(2) {
      ["date"]=>
      string(10) "2011-06-11"
      ["count"]=>
      float(10)
    }
    [2]=>
    array(2) {
      ["date"]=>
      string(10) "2011-06-10"
      ["count"]=>
      float(7)
    }
  }
  ["count"]=>
  float(34)
  ["keys"]=>
  int(3)
  ["ok"]=>
  float(1)
}
</pre>




<h4>Deploy to production?</h4>


<p>Until now, the demo is still a toy. If you want to deploy it to production, there are more work need to to be done. Take a look at the <a href='http://www.mongodb.org/display/DOCS/Admin+Zone'>admin zone</a></p>

<p>For my feature implemention, I will consider <a href='http://www.mongodb.org/display/DOCS/Replication'>Replication</a> next step.</p>

<p>Summary:</p>

<p>This is not a <a href='http://www.mongodb.org/display/DOCS/Tutorial'>toturial</a> about how to use MongoDB. It is just a example that can use nosql db in your production.</p>

<p>Reference:</p>

<ul>
<li><a href='http://try.mongodb.org/'>A Tiny MongoDB Browser Shell (mini tutorial included)</a></li>
<li><a href='https://github.com/mongodb/mongo/tree/master/jstests/'>JsTest</a></li>
</ul>



				<div class="post-metadata">
					June 12, 2011 | 
					<a href='/2011/06/12/nosql-db-try.html#disqus_thread'>View Comments</a>
					
						
							| 
						
						<a href='/tags.html#mysql'>mysql</a>
						, 
					
						
						<a href='/tags.html#nosql'>nosql</a>
						, 
					
						
						<a href='/tags.html#mongodb'>mongodb</a>
						
					 
				</div>

			</div>
		
			<div class="post" id="postid-/2011/05/24/mysql-index-merge">
				<h3 class="title"><a href="/2011/05/24/mysql-index-merge.html">When To Use Combine Index</a></h3>
				
				<p>There are already a lot of posts which gave a introduction of what index merge is in MySQL. One of them is:</p>

<p><a href='http://brian.moonspot.net/2008/04/22/playing-with-mysql-index-merge/'>Playing with MySQL's index merge</a></p>

<p>Today I just noticed the combined index also can be affected by the single column index. For example:</p>

<ol>
<li>Let's say we have a table named table1 which have 100,000 items. The size of this table is 35MB.</li>
</ol>


<p>Table structure:</p>

<pre>
CREATE TABLE `table1` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `name` varchar(20) DEFAULT NULL,
  `status1` int(11) DEFAULT NULL,
  `status2` int(11) DEFAULT NULL,
  `status3` int(11) DEFAULT NULL,
  `status4` int(11) DEFAULT NULL,
  `status5` int(11) DEFAULT NULL,
  `status6` int(11) DEFAULT NULL,
  PRIMARY KEY (`id`),
  UNIQUE KEY `table1_name_unique` (`name`),
  KEY `table1_status1` (`status1`),
  KEY `table1_status2` (`status2`),
  KEY `table1_status3` (`status3`),
  KEY `table1_status4` (`status4`),
  KEY `table1_status5` (`status5`),
  KEY `table1_status6` (`status6`),
  KEY `table1_combine_index` (`status1`,`status2`,`status3`,`status4`,`status5`,`status6``)
) ENGINE=InnoDB DEFAULT CHARSET=utf8
</pre>


<p>We have a query need to select items from table1 table with checking all the status columns in where clause. Let's do a explain:</p>

<pre>
explain select * from table1 where status1=1 and status2=1 and status3=1 and status4=1 and status5=1 and status6=1  
</pre>


<p>Explain result:</p>

<pre>
  select_type: SIMPLE
  table: table1
  type: index_merge
  possible_keys: PRIMARY,table1_status1,table1_status2,table1_status3,table1_status4,table1_status5,table1_status6,table1_combine_index
  key: table1_status1,table1_status2,table1_status3,table1_status4,table1_status5,table1_status6
  key_len: 1,1,4,4,4,5
  refs: NULL
  rows: 1955
  Extra: Using intersect(table1_status1,table1_status2,table1_status3,table1_status4,table1_status5,table1_status6); Using where
</pre>


<p>The select query takes <b>3.5ms</b> by intersecting indexes.</p>

<p>What happened if we force index to use table1_combine_index:</p>

<pre>
explain select * from table1 force index (table1_combine_index)  where status1=1 and status2=1 and status3=1 and status4=1 and status5=1 and status6=1  
</pre>


<p>Explain result:</p>

<pre>
  select_type: SIMPLE
  table: table1
  type: ref
  possible_keys: table1_combine_index
  key: table1_combine_index
  key_len: 9
  refs: const,const
  rows: 62590
  Extra: Using where
</pre>


<p>The select query takes <b>10.5ms</b> by using combine index.</p>

<p>In this example, intersecting index is more useful than combine index. There is an article give a more detailed explanation why it works like this:</p>

<p><a href='http://www.mysqlperformanceblog.com/2009/09/19/multi-column-indexes-vs-index-merge/'>Multi Column indexes vs Index Merge</a></p>

<ol>
<li>Now it's time to make this example a little complicated.</li>
</ol>


<p>We have another table named table2, the structure looks like:</p>

<pre>
CREATE TABLE `table2` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `table1_id` int(11) NOT NULL,
  `column1` datetime NOT NULL,
  `column2` varchar(255) NOT NULL,
  `column3` text,
  `column4` tinyint(4) NOT NULL,
  `column5 ` tinyint(4) NOT NULL,
  `column6 ` tinyint(4) NOT NULL,
  `column7` varchar(255) NOT NULL,
  PRIMARY KEY (`id`),
  UNIQUE KEY `column7 ` (`column7 `),
  KEY `table2_FI_1` (`table1_id `)
) ENGINE=InnoDB DEFAULT CHARSET=utf8
</pre>


<p>There are 20,000 rows in table2, with size 11MB. We have a feature request need to join table1 with table2 and sort by table2's id.</p>

<pre>
SELECT sql_no_cache * FROM table2 LEFT JOIN table1 ON (table2.table1_id = table1.id) WHERE table1.status1=1 and table1.status2=1 and table1.status3=1 and table1.status4=1 and table1.status5=1 and table1.status6=1 ORDER BY table2.id DESC LIMIT 10;
</pre>


<p>It takes <b>3s</b> to finish the query. The explain tells you:</p>

<pre>
  select_type: SIMPLE
  table: table1
  type: index_merge
  possible_keys: PRIMARY,`table1_status1`,`table1_status2`,`table1_status3`,`table1_status4`,`table1_status5`,`table1_status6`,`table1_combine_index`
  key: `table1_status1`,`table1_status2`,`table1_status3`,`table1_status4`,`table1_status5`,`table1_status6`
  key_len: 1,1,4,4,4,5
  refs: NULL
  rows: 1955
  Extra: Using intersect(`table1_status1`,`table1_status2`,`table1_status3`,`table1_status4`,`table1_status5`,`table1_status6`); Using where
  
  ---
  select_type: SIMPLE
  table: table2
  type: ref
  possible_keys: table2_FI_1
  key: table2_FI_1
  key_len: 4
  refs: table1.id
  rows: 1
  Extra:  
</pre>


<p>Now I want to remove these single column indexes in table1 to see what will happen:</p>

<pre>
  select_type: SIMPLE
  table: table2
  type: index
  possible_keys: table2_FI_1
  key: PRIMARY
  key_len: 4
  refs: 
  rows: 10
  Extra:
  
  ---
  
  select_type: SIMPLE
  table: table1
  type: eq_ref
  possible_keys: PRIMARY,table1_combine_index
  key: PRIMARY
  key_len: 4
  refs: table2.table1_id
  rows: 1
  Extra: Using where
</pre>


<p>After removing the single column indexes in table 1, this select query only takes <b>2.4ms</b>. To explain this, we can simply treat (status1,status2,status3,status4,status5,status6) as one column in table1. I think the single columns indexes affected the 'join' performance. MySQL need to use these single indexes to filter the table1 firstly and then make a join with table2.</p>

<p>Summary:</p>

<p>Combine index is not always better than index merge. To know which one is better, explain your query, analyze it and adjust the index.</p>


				<div class="post-metadata">
					May 24, 2011 | 
					<a href='/2011/05/24/mysql-index-merge.html#disqus_thread'>View Comments</a>
					
						
							| 
						
						<a href='/tags.html#mysql'>mysql</a>
						
					 
				</div>

			</div>
		
			<div class="post" id="postid-/2011/05/06/upgrade-ubuntu-fpm-404-error">
				<h3 class="title"><a href="/2011/05/06/upgrade-ubuntu-fpm-404-error.html">Nginx, PHP-FPM, 404 error after upgrading to Ubuntu 11.04</a></h3>
				
				<p>After upgrading from ubuntu 10.10 to ubuntu 11.04 my local site didn't work anymore. It reponsed with a 404 page.</p>

<p>After researcing for a while, I found the root should be put outside the location property:
Before:</p>

<pre>
server {
  server_name  localhost;

  location / {
        root   /var/www;
        index  index.php index.html index.htm;
    }
 ....
}

</pre>


<p>After:</p>

<pre>
server {

  root   /var/www;
  index  index.php index.html index.htm;
  server_name  localhost;

 ....
}
</pre>


<p>Now it works, but have no idea what has been changed since Ubuntu upgrade.</p>


				<div class="post-metadata">
					May 06, 2011 | 
					<a href='/2011/05/06/upgrade-ubuntu-fpm-404-error.html#disqus_thread'>View Comments</a>
					
						
							| 
						
						<a href='/tags.html#ubuntu'>ubuntu</a>
						, 
					
						
						<a href='/tags.html#php-fpm'>php-fpm</a>
						
					 
				</div>

			</div>
		
			<div class="post" id="postid-/2011/05/01/solve-ubuntu1104-wifi-issue">
				<h3 class="title"><a href="/2011/05/01/solve-ubuntu1104-wifi-issue.html">Solve Wireless Issue When Upgrading From 10.10 to 11.04</a></h3>
				
				<p>After upgrading from ubuntu 10.10 to ubuntu 11.04 the wireless stop working.</p>

<p>The first step, I was using <a href="https://help.ubuntu.com/community/WifiDocs/WirelessTroubleShootingGuide">ubuntu trouble shooting</a> to detect the issue.</p>

<ol type="a">
<li>Detail whether there are software or hardware blocks on your rf devices. To get a list of devices and their hardware and software status, try "sudo rfkill list".</li>
</ol>


<pre>
~$ sudo rfkill list
0: hp-wifi: Wireless LAN
    Soft blocked: yes
    Hard blocked: yes
</pre>


<p>Unblock your devices by "sudo rfkill unblock 0".</p>

<ol type="a">
<li>Check for Device Recognition for my HP laptop(amd64)</li>
</ol>


<pre>
~$ sudo lshw -C network
  *-network UNCLAIMED     
       description: Network controller
       product: BCM4311 802.11a/b/g
       vendor: Broadcom Corporation
       physical id: 0
       bus info: pci@0000:30:00.0
       version: 01
       width: 32 bits
       clock: 33MHz
       capabilities: pm msi pciexpress bus_master cap_list
       configuration: latency=0
       resources: memory:c8000000-c8003fff
  *-network
       description: Ethernet interface
       product: NetXtreme BCM5788 Gigabit Ethernet
       vendor: Broadcom Corporation
       physical id: 1
       bus info: pci@0000:02:01.0
       logical name: eth0
       version: 03
       serial: 00:17:08:37:6a:64
       size: 100Mbit/s
       capacity: 1Gbit/s
       width: 32 bits
       clock: 66MHz
       capabilities: pm vpd msi bus_master cap_list ethernet physical tp 10bt 10bt-fd 100bt 100bt-fd 1000bt 1000bt-fd autonegotiation
       configuration: autonegotiation=on broadcast=yes driver=tg3 driverversion=3.116 duplex=full firmware=5788-v3.26 ip=192.168.1.103 latency=64 link=yes mingnt=64 multicast=yes port=twisted pair speed=100Mbit/s
       resources: irq:23 memory:d4000000-d400ffff
</pre>


<p>Here I can see 'tg3' driver was using. And by checking the loaded module the tg3 is there.</p>

<pre>
~$ sudo lsmod
</pre>


<p>If your driver was not loaded, you can load it by "sudo modprobe <module>"</p>

<ol type="a">
<li>Identify PCI devices with PCI ID.</li>
</ol>


<pre>
~$ sudo lspci -v | grep Ethernet
02:01.0 Ethernet controller: Broadcom Corporation NetXtreme BCM5788 Gigabit Ethernet (rev 03)

~$ sudo lspci -v | grep Network
30:00.0 Network controller: Broadcom Corporation BCM4311 802.11a/b/g (rev 01)
</pre>


<ol type="a">
<li>Check the addtional drivers, I found "Broadcom STA wireless driver" was using.</li>
</ol>


<p>Everything looks good until now. Driver was working and was recognized. So I guess the issue might be the compatibility with new kernel?</p>

<ol type="a">
<li>With the help from google.</li>
</ol>


<p>i). Someone solve it by install <a herf="http://ubuntuforums.org/showthread.php?t=1653157">linux-backports-modules-wireless-maverick-generic</a>. It is interesting to know what <a hef="https://help.ubuntu.com/community/UbuntuBackports">backports</a> is.</p>

<p>Unfortunately it didn't work for me.</p>

<p>ii). So I tried the solution in this <a href="http://ubuntuforums.org/showthread.php?t=1653157&page=2">thread</a> by disable my "Broadcom STA wireless driver" and install b43.</p>

<pre>
Removing "bcmwl-kernel-source" by using Synaptic Package Manager
Then installing "firmware-b43-installer" and "b43-fwcutter" again by Synaptic Package Manager. 
</pre>


<p>At the end of step e, and by rebooting laptop, the wifi issue was fixed. If you still has the issue, I suggest check the trouble shooting tutorial again. It is really helpful.</p>

<p>Reference:</p>

<p>1.http://linuxfans.keryxproject.org/?page_id=27</p>

<p>2.http://www.ubuntumini.com/2009/11/broadcom-wireless-driver-fix-in-karmic.html</p>


				<div class="post-metadata">
					May 01, 2011 | 
					<a href='/2011/05/01/solve-ubuntu1104-wifi-issue.html#disqus_thread'>View Comments</a>
					
						
							| 
						
						<a href='/tags.html#ubuntu'>ubuntu</a>
						, 
					
						
						<a href='/tags.html#wireless'>wireless</a>
						
					 
				</div>

			</div>
		
			<div class="post" id="postid-/2011/04/22/what-rabbitmq-cluster-can-do">
				<h3 class="title"><a href="/2011/04/22/what-rabbitmq-cluster-can-do.html">What RabbitMQ Cluster Can Do</a></h3>
				
				<h3>What RabbitMQ cluster can do - Scaling and Reliability</h3>


<ul>
<li><b>Example 1</b>:</li>
</ul>


<p>All data/state required for the operation of a RabbitMQ broker is replicated across all nodes.</p>

<p>Let's take an example to help you understand better.</p>

<p>There is a publisher which publish 10 messages to RabbitMQ broker(*1).</p>

<p>|Publisher| --> |10 Messages| --> |Broker( = Node_A + Node_B)|</p>

<p>So Node_A will receive Message 1, Message 3, 5, 7, 9; Node_B will receive Message 2, Message 4, 6, 8, 10.</p>

<ul>
<li><b>Example 2</b>:</li>
</ul>


<p>We still use the above example. If the Node_A crashed when it is consuming the messages, what happens?</p>

<p>Before Node_A crashed (I simply powered off this machine):</p>

<p>Node_A finished Message 1, Message 3, and it is starting to consume Message 5;</p>

<p>Node_B finished Message 2, Message 4 and it is starting to consume Message 6.</p>

<p>After Node_A crashed:</p>

<p>Node_A stopped working;</p>

<p>Node_B finished Message 6, Message 7, Message 8, Message 9, Message 10 and Message 5.</p>

<p>Yes, as you can see, even Node_A dies unexpected. Broker still can get the status of Message 5 and send it to Node_B.
And you can find following explanation:</p>

<pre>
  If a node goes down or becomes unreachable what effects can this have on the cluster? Do things 'hang' for a bit?
  
  Topology change operations (see above) could potentially pause operation for a brief time but they will complete eventually. We use the net_kernel erlang module to do monitoring between nodes. The default "tick" time there is 60 seconds but this can be reduced. Further, in the event of a failure, any communication between the nodes will likely result in an error being generated and detected immediately: i.e. the only time at which you would not know about a node failure for 60 seconds is if there was no communication between the nodes for that amount of time.
  
  ....
  
</pre>




<h3>What RabbitMQ cluster can not do - High Availability</h3>


<p>So the 60 seconds is what RabbitMQ can not do. We call it high availability.</p>

<pre>
...
Whilst RabbitMQ also supports clustering, clustering is intended to facilitate scalability, not availability. Thus in a cluster, if a node fails, queues which were on the failed node are lost. With the high availability setup described in this guide, when a node fails, the durable queues and the persistent messages within them can be recovered by a different node.
...
</pre>


<p>To build a high availability and scalable application, you can take a look <a href='http://www.rabbitmq.com/pacemaker.html'>RabbitMQ Placemaker</a></p>

<p>References:</p>

<ol>
<li>RabbitMQ broker - a logical grouping of one or several Erlang nodes, each running the RabbitMQ application and sharing users, virtual hosts, queues, exchanges, etc. Sometimes we refer to the collection of nodes as a cluster.</li>
</ol>



				<div class="post-metadata">
					April 22, 2011 | 
					<a href='/2011/04/22/what-rabbitmq-cluster-can-do.html#disqus_thread'>View Comments</a>
					
						
							| 
						
						<a href='/tags.html#rabbitmq'>rabbitmq</a>
						
					 
				</div>

			</div>
		
			<div class="post" id="postid-/2011/03/08/do-we-still-need-scrum">
				<h3 class="title"><a href="/2011/03/08/do-we-still-need-scrum.html">Do we still need scrum if ...</a></h3>
				
				<p>Just learned an interesting point from <a href='http://architects.dzone.com/articles/balancing-software'>'balance software' post</a>:</p>

<h4>When Scrum has died</h4>


<pre>
  In the journey of dramatic improvements to bring your code base under control, there are few things that you should take notice off.

  * An architecture will emerge that supports the design of the resident parts.  Things fit together sweetly and each part supports the other part in symbiotic relationships.
  * The code base will get smaller and the team will shrink to, perhaps,  just 2 or 3 people.
  * Each developer will take on greater responsibility and will find it difficult to break core principles.  The act of living those principles will result in a values that don't need to be listed on a poster on the wall.
  * The scrum master will become redundant.
  * The product owner will do more by working directly with the developers.
  * The developers will represent the interest of their customers directly.
  * The bottleneck will shift from development to the product owner and eventually the customer.
</pre>


<p>In my opinion, Scrum is used for company to delivery features to users quickly and interactively. As a team, with scrum you can easily prove your works after a short time. You don't have to wait for one year or longer. And big feature can be split into small ones. Everyone know what need to be done in following weeks. You don't have to write so many documents to trace what's going on. Ideally, as the authors said, if the code base can be made smaller and smaller. And the new feature will be just a plugin to your platform. Of course you don't need scrum. Should we call it as 'factory model'? As workers(developers) just need to collect the feature request and compose it by some existing functions. And plug it into the platform(codebase). I have not seen a company who has such a powerful platform. Will the bottleneck be the platform itself then?</p>


				<div class="post-metadata">
					March 08, 2011 | 
					<a href='/2011/03/08/do-we-still-need-scrum.html#disqus_thread'>View Comments</a>
					
						
							| 
						
						<a href='/tags.html#scrum'>scrum</a>
						
					 
				</div>

			</div>
		
			<div class="post" id="postid-/2011/03/02/server-monitor">
				<h3 class="title"><a href="/2011/03/02/server-monitor.html">Web Server Memory Monitor</a></h3>
				
				<h2>free-m</h2>


<pre>
free-m: to see how much memory you are currently using
</pre>


<p>Output:
<code>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; total &nbsp;&nbsp; used&nbsp;&nbsp; free&nbsp;&nbsp;&nbsp; shared buffers cached<br> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Mem:&nbsp;90&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 85 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 4&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 0 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 3&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 34<br>
-/+ buffers/cache:&nbsp; 46&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 43<br> &nbsp;&nbsp;&nbsp;&nbsp;Swap:&nbsp;&nbsp; 9&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 0 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 9 </code>
The top row 'used' (85) value will almost always nearly match the top row mem value (90).  Since Linux likes to use any spare memory to cache disk blocks (34).</p>

<p>The key used figure to look at is the buffers/cache row used value (46).  This is how much space your applications are currently using.  For best performance, this number should be less than your total (90) memory.  To prevent out of memory errors, it needs to be less than the total memory (90) and swap space (9).</p>

<p>If you wish to quickly see how much memory is free look at the buffers/cache row free value (43). This is the total memory (90)- the actual used (46). (90 - 46 = 44, not 43, this will just be a rounding issue)</p>

<h2>ps aux</h2>


<pre>
ps aux: to see where all your memory is going.That will show the percentage of memory each process is using.  You can use it to identify the top memory users (usually Apache, MySQL and Java processes).
</pre>


<p>Output:
<code>
USER PID %CPU %MEM VSZ&nbsp;&nbsp;&nbsp;&nbsp; RSS&nbsp;&nbsp; TTY&nbsp;&nbsp; STAT
&nbsp; START TIME COMMAND<br>
root 854 0.5&nbsp; 39.2 239372&nbsp; 36208 pts/0 S&nbsp;&nbsp;&nbsp;&nbsp; 22:50 0:05
/usr/local/jdk/bi<br>
n/java -Xms16m -Xmx64m -Djava.awt.headless=true -Djetty.home=/opt/jetty -cp /opt<br>
/jetty/ext/ant.jar:/opt/jetty/ext/jasper-compiler.jar:/opt/jetty/ext/jasper-runt<br>
ime.jar:/opt/jetty/ext/jcert.jar:/opt/jetty/ext/jmxri.jar:/opt/jetty/ext/jmxtool
</code>
We can see that java is using up 39.2% of the available memory.</p>

<h2>vmstat</h2>


<pre>
vmstat:helps you to see, among other things, if your server is swapping.
</pre>


<p><code>
- vmstat 1 2
   procs                      memory    swap          io     system         cpu
 r  b  w   swpd   free   buff  cache  si  so    bi    bo   in    cs  us  sy  id
 0  0  0  39132   2416    804  15668   4   3     9     6  104    13   0   0 100
 0  0  0  39132   2416    804  15668   0   0     0     0   53     8   0   0 100
 0  0  0  39132   2416    804  15668   0   0     0     0   54     6   0   0 100
</code>
The first row shows your server averages.  The si (swap in) and so (swap out) columns show if you have been swapping (i.e. needing to dip into 'virtual' memory) in order to run your server's applications.  The si/so numbers should be 0 (or close to it).  Numbers in the hundreds or thousands indicate your server is swapping heavily.  This consumes a lot of CPU and other server resources and you would get a very (!) significant benefit from adding more memory to your server.</p>

<p>Some other columns of interest: The r (runnable) b (blocked) and w (waiting) columns help see your server load.  Waiting processes are swapped out.  Blocked processes are typically waiting on I/O.  The runnable column is the number of processes trying to something.  These numbers combine to form the 'load' value on your server.  Typically you want the load value to be one or less per CPU in your server.</p>

<p>The bi (bytes in) and bo (bytes out) column show disk I/O (including swapping memory to/from disk) on your server.</p>

<p>The us (user), sy (system) and id (idle) show the amount of CPU your server is using.  The higher the idle value, the better.</p>

<h2>Resolving: High Java Memory Usage</h2>


<p>Java processes can often consume more memory than any other application running on a server.</p>

<p>Java processes can be passed a -Xmx option.  This controls the maximum Java memory heap size.  It is important to set a limit on the heap size, otherwise the heap will keep increasing until you get out of memory errors on your VPS (resulting in the Java process - or even some other, random, process - dying.</p>

<p>Usually the setting can be found in your /usr/local/jboss/bin/run.conf or /usr/local/tomcat/bin/setenv.sh config files.  And your RimuHosting default install should have a reasonable value in there already.</p>

<p>If you are running a custom Java application, check there is a -XmxNNm (where NN is a number of megabytes) option on the Java command line.</p>

<p>The optimal -Xmx setting value will depend on what you are running.  And how much memory is available on your server.</p>

<p>From experience we have found that Tomcat often runs well with an -Xmx between 48m and 64m.  JBoss will need a -Xmx of at least 96m to 128m.  You can set the value higher.  However, you should ensure that there is memory available on your server.</p>

<p>To determine how much memory you can spare for Java, try this: stop your Java process; run free -m; subtract the 'used' value from the "-/+ cache" row from the total memory allocated to your server and then subtract another 'just in case' margin of about 10% of your total server memory.  The number you come up with is a rough indicator of the largest -Xmx setting you can use on your server.</p>

<h2>Resolving: High Apache Memory Usage</h2>


<p>Apache can be a big memory user.  Apache runs a number of 'servers' and shares incoming requests among them.  The memory used by each server grows, especially when the web page being returned by that server includes PHP or Perl that needs to load in new libraries.  It is common for each server process to use as much as 10% of a server's memory.</p>

<p>To reduce the number of servers, you can edit your httpd.conf file.  There are three settings to tweak: StartServers, MinSpareServers, and MaxSpareServers.  Each can be reduced to a value of 1 or 2 and your server will still respond promptly, even on quite busy sites.  Some distros have multiple versions of these settings depending on which process model Apache is using.  In this case, the 'prefork' values are the ones that would need to change.</p>

<p>To get a rough idea of how to set the MaxClients directive, it is best to find out how much memory the largest apache thread is using. Then stop apache, check the free memory and divide that amount by the size of the apache thread found earlier. The result will be a rough guideline that can be used to further tune (up/down) the MaxClients directive. The following script can be used to get a general idea of how to set MaxClients for a particular server:</p>

<pre class="codebox">
#!/bin/bash
echo "This is intended as a guideline only!"
if [ -e /etc/debian_version ]; then
    APACHE="apache2"
elif [ -e /etc/redhat-release ]; then
    APACHE="httpd"
fi
RSS=`ps -aylC $APACHE |grep "$APACHE" |awk '{print $8'} |sort -n |tail -n 1`
RSS=`expr $RSS / 1024`
echo "Stopping $APACHE to calculate free memory"
/etc/init.d/$APACHE stop &amp;amp;ampamp&gt; /dev/null
MEM=`free -m |head -n 2 |tail -n 1 |awk '{free=($4); print free}'`
echo "Starting $APACHE again"
/etc/init.d/$APACHE start &amp;amp;&gt; /dev/null
echo "MaxClients should be around" `expr $MEM / $RSS`
</pre>


<p>Note: httpd.conf should be tuned correctly on our newer WBEL3 and FC2 distros.  Apache is not installed by default on our Debian distros (since some people opt for Apache 2 and others prefer Apache 1.3).  So this change should only be necessary if you have a Debian distro.</p>

<p>from http://modperlbook.org/html/11-2-Setting-the-MaxRequestsPerChild-Directive.html: "Setting MaxRequestsPerChild to a non-zero limit solves some memory-leakage problems caused by sloppy programming practices and bugs, whereby a child process consumes a little more memory after each request. In such cases, and where the directive is left unbounded, after a certain number of requests the children will use up all the available memory and the server will die from memory starvation."</p>

<h2>Resolving: High MySQL Memory Usage</h2>


<p><code>
-- if your are not using the innodb table manager, then just skip it to save some memory
-- skip-innodb
innodb_buffer_pool_size = 16k
key_buffer_size = 16k
myisam_sort_buffer_size = 16k
query_cache_size = 1M
</code></p>

<h2>Troubleshooting Irregular Out Of Memory Errors</h2>


<p>Sometimes a server's regular memory usage is fine.  But it will intermittently run out of memory.  And when that happens you may lose trace of what caused the server to run out of memory.</p>

<p>In this case you can setup a script (see below) that will regularly log your server's memory usage.  And if there is a problem you can check the logs to see what was running.</p>

<p><code>
wget http://proj.ri.mu/memmon.sh -O /root/memmon.sh
chmod +x /root/memmon.sh
</code></p>

<pre>
-- create a cronjob that runs every few minutes to log the memory usage
echo '0-59/10 * * * * root /root/memmon.sh >> /root/memmon.txt' > /etc/cron.d/memmon
/etc/init.d/cron* restart 

-- create a logrotate entry so the log file does not get too large
echo '/root/memmon.txt {}' > /etc/logrotate.d/memmon

</pre>


<p>This article was copied from http://rimuhosting.com/howto/memory.jsp.</p>


				<div class="post-metadata">
					March 02, 2011 | 
					<a href='/2011/03/02/server-monitor.html#disqus_thread'>View Comments</a>
					
						
							| 
						
						<a href='/tags.html#performance'>performance</a>
						, 
					
						
						<a href='/tags.html#memory'>memory</a>
						
					 
				</div>

			</div>
		
		
		<div class="paging">
		
			<a href="/page4" class="previous">&#x25C4; Previous</a>
		
		
			
			  <a href="/page2" class="next">Next &#x25BA;</a>
			
		
		</div>

  </ul>
</div>
</div>

	</div>
  
  <div class="footer">
		<div id="copyright">
			Copyright &copy; 2011 Joshua Chi - Powered by <a href="http://github.com/mojombo/jekyll">Jekyll</a> and <a href="http://github.com/">Github</a>
		</div>
  </div>    
</div>

</body>
</html>
